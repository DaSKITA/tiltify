{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d0665a",
   "metadata": {},
   "source": [
    "# Tiltify\n",
    "Project to test out Natural Language Processing on Labeled Privacy Policies. The annotations of the policies are performed in the TILT Schema The goal is to infer TILT Labels for a given privacy policy and thus perform automated annotations for these policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d14a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65932c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "config_file_path = 'config.yml'\n",
    "with open(config_file_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "username = config['username']\n",
    "password = config['password']\n",
    "database = config['database']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ff4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to database\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(f'mongodb://{username}:{password}@127.0.0.1:27017')\n",
    "db = client[database]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "188bfb4a-1dd8-4ac0-b7c2-938e8a79f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting examples\n",
    "annotation_cursor = db.annotation.find({'label': {'$regex': 'Right to.*'}})\n",
    "good_examples = []\n",
    "bad_examples = []\n",
    "bad_examples_ids = []\n",
    "\n",
    "for annotation in annotation_cursor:\n",
    "    if annotation['text'].count(' ') > 10:\n",
    "        good_examples.append(annotation)\n",
    "    elif annotation['text'].count(' ') < 3:\n",
    "        bad_examples.append(annotation)\n",
    "        if annotation['task'] not in bad_examples_ids:\n",
    "            bad_examples_ids.append(annotation['task'])\n",
    "            \n",
    "task_cursor = db.task.find()\n",
    "bad_examples_names = []\n",
    "grey_zone_examples_names = []\n",
    "for task in task_cursor:\n",
    "    if task['_id'] in bad_examples_ids:\n",
    "        bad_examples_names.append(task['name'])\n",
    "    elif 'parent' not in task:\n",
    "        grey_zone_examples_names.append(task['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59a3df5d-eda5-439e-bb48-3af04a6f1804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|facebook|grey|-|\n",
      "|bnp_paribas|grey|-|\n",
      "|tesco|grey|-|\n",
      "|carrefour|grey|-|\n",
      "|signal|grey|-|\n",
      "|siemens|grey|-|\n",
      "|verivox|grey|-|\n",
      "|webde|grey|-|\n",
      "|stihl|grey|-|\n",
      "|vw|grey|-|\n",
      "|xing|grey|-|\n",
      "|h&m|grey|-|\n",
      "|takeda|grey|-|\n",
      "|whatsapp|grey|-|\n",
      "|dhl|grey|-|\n",
      "|ryanair|grey|-|\n",
      "|qwant|grey|-|\n",
      "|telefonica|grey|-|\n",
      "|ltur|grey|-|\n",
      "|viessmann|grey|-|\n",
      "|bvg|grey|-|\n",
      "|amazon|grey|-|\n",
      "|google|grey|-|\n",
      "|Amazon Alexa Terms of Use|grey|-|\n",
      "|Google Assistant|grey|-|\n",
      "|Siemens AG|grey|-|\n",
      "|Zoom|grey|-|\n",
      "|Cisco|grey|-|\n",
      "|Deutsche Bahn|grey|-|\n",
      "|ARD Mediathek|grey|-|\n",
      "|Dropbox|grey|-|\n",
      "|Github|grey|-|\n",
      "|Spiegel Online|grey|-|\n",
      "|Discord|grey|-|\n",
      "|Twitter|grey|-|\n",
      "|SPD|grey|-|\n",
      "|GRÃœNE|grey|-|\n",
      "|Mircosoft Teams|grey|-|\n",
      "|Fitbit|grey|-|\n",
      "|Runtastic|grey|-|\n",
      "|Niantic (Pokemon Go)|grey|-|\n",
      "|Fiducia|grey|-|\n",
      "|Duden|grey|-|\n",
      "|Chefkoch|grey|-|\n",
      "|Setting.io|grey|-|\n",
      "|Shopify|grey|-|\n",
      "|Tagesschau App|grey|-|\n",
      "|Twitch|grey|-|\n",
      "|Adobe|grey|-|\n",
      "|giki|grey|-|\n",
      "|endcitizensunited|grey|-|\n"
     ]
    }
   ],
   "source": [
    "# HackMD format\n",
    "\n",
    "for i in grey_zone_examples_names:\n",
    "    print(f'|{i}|grey|-|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20224473-c73d-4412-bce5-5ca6c0c4bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# good examples\n",
    "for annotation in good_examples[:5]:    \n",
    "    print(f\"Label: {annotation['label']}\\nText: {annotation['text']}\")\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "print(f\"#goodexamples: {len(good_examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb8b7fe-7cce-4513-84a1-1a0924e9e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad examples\n",
    "for annotation in bad_examples[:5]:    \n",
    "    print(f\"Label: {annotation['label']}\\nText: {annotation['text']}\")\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "print(f\"#badexamples: {len(bad_examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebd22c6-fad4-4ead-aceb-dd1b2100f4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of tasks with bad examples\n",
    "print('bad examples names:')\n",
    "print(bad_examples_names)\n",
    "print(f\"#bad examples names: {len(bad_examples_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf8932d-6110-4eea-adb7-2dd0dc31dc1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# iterate through all tasks and get sentence dataset\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "nlp = spacy.load('de_core_news_lg')\n",
    "nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n",
    "task_cursor = db.task.find({})\n",
    "\n",
    "de_data = []\n",
    "en_data = []\n",
    "counter = 0\n",
    "\n",
    "for task in tqdm(task_cursor):\n",
    "    \n",
    "    # get text and id of task\n",
    "    text = task['text']\n",
    "    doc_id = task['_id']\n",
    "    \n",
    "    # find all annotations of this task and extract them\n",
    "    annotation_cursor = db.annotation.find({'task': doc_id, 'label': {'$regex': 'Right to.*'}})\n",
    "    annotations = []\n",
    "    for annotation in annotation_cursor:\n",
    "        annotations.append({'start': annotation['start'], 'end': annotation['end'], 'label': annotation['label'], 'text': annotation['text']})\n",
    "        \n",
    "    if not annotations:\n",
    "        continue\n",
    "        \n",
    "    # iterate over text and save sentences\n",
    "    doc = nlp(text)\n",
    "    for sentence in list(doc.sents):\n",
    "        is_sentence_appended = False\n",
    "        sentence_start = len(text.split(str(sentence))[0]) + 1\n",
    "        sentence_end = sentence_start + len(str(sentence))\n",
    "        for annotation in annotations:\n",
    "            if sentence_start <= annotation['start'] <= sentence_end or\\\n",
    "                sentence_start <= annotation['end'] <= sentence_end or\\\n",
    "                annotation['start'] <= sentence_start <= annotation['end'] or\\\n",
    "                annotation['start'] <= sentence_end <= annotation['end']:\n",
    "                    if sentence._.language['en']:\n",
    "                        en_data.append({'sentence': str(sentence), 'label': annotation['label']})\n",
    "                        is_sentence_appended = True\n",
    "                    elif sentence._.language['de']:\n",
    "                        de_data.append({'sentence': str(sentence), 'label': annotation['label']})\n",
    "                        is_sentence_appended = True\n",
    "        if not is_sentence_appended:\n",
    "            if sentence._.language['en']:\n",
    "                en_data.append({'sentence': str(sentence), 'label': annotation['label']})\n",
    "            elif sentence._.language['de']:\n",
    "                de_data.append({'sentence': str(sentence), 'label': annotation['label']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa160bbd-da7b-4029-8666-804680514594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "import pandas\n",
    "\n",
    "de_df = pandas.DataFrame.from_dict(de_data)\n",
    "print(de_df)\n",
    "en_df = pandas.DataFrame.from_dict(en_data)\n",
    "print(en_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc2c27-a5ad-4d56-bc2f-6b50665b0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv files\n",
    "de_df.to_csv('~/Documents/DaSKITA/playground/tiltify/data/de_sentence_data.csv')\n",
    "en_df.to_csv('~/Documents/DaSKITA/playground/tiltify/data/en_sentence_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c00a82eacfe0370be8326cca920297af08c3bb7bdac9e41c299bfef56ad4a128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
