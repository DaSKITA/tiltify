{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d0665a",
   "metadata": {},
   "source": [
    "# Tiltify\n",
    "Project to test out Natural Language Processing on Labeled Privacy Policies. The annotations of the policies are performed in the TILT Schema The goal is to infer TILT Labels for a given privacy policy and thus perform automated annotations for these policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d14a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65932c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "config_file_path = 'config.yml'\n",
    "with open(config_file_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "username = config['username']\n",
    "password = config['password']\n",
    "database = config['database']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ff4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to database\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(f'mongodb://{username}:{password}@127.0.0.1:27017')\n",
    "db = client[database]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17edd887-9e9f-45b6-a316-004675fb93d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "188bfb4a-1dd8-4ac0-b7c2-938e8a79f4b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grey_zone_examples_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r7/l98msrn96b980t7mm23zjzlm0000gn/T/ipykernel_5962/1512530024.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mbad_examples_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mgrey_zone_examples_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'grey_zone_examples_names' is not defined"
     ]
    }
   ],
   "source": [
    "# getting examples\n",
    "annotation_cursor = db.annotation.find({'label': {'$regex': 'Right to.*'}})\n",
    "good_examples = []\n",
    "bad_examples = []\n",
    "bad_examples_ids = []\n",
    "\n",
    "for annotation in annotation_cursor:\n",
    "    if annotation['text'].count(' ') > 10:\n",
    "        good_examples.append(annotation)\n",
    "    elif annotation['text'].count(' ') < 3:\n",
    "        bad_examples.append(annotation)\n",
    "        if annotation['task'] not in bad_examples_ids:\n",
    "            bad_examples_ids.append(annotation['task'])\n",
    "            \n",
    "task_cursor = db.task.find()\n",
    "bad_examples_names = []\n",
    "grey_zone_examples_names = []\n",
    "for task in task_cursor:\n",
    "    if task['_id'] in bad_examples_ids:\n",
    "        bad_examples_names.append(task['name'])\n",
    "    else:\n",
    "        grey_zone_examples_names.append(task['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20224473-c73d-4412-bce5-5ca6c0c4bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# good examples\n",
    "for annotation in good_examples[:5]:    \n",
    "    print(f\"Label: {annotation['label']}\\nText: {annotation['text']}\")\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "print(f\"#goodexamples: {len(good_examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb8b7fe-7cce-4513-84a1-1a0924e9e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad examples\n",
    "for annotation in bad_examples[:5]:    \n",
    "    print(f\"Label: {annotation['label']}\\nText: {annotation['text']}\")\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "print(f\"#badexamples: {len(bad_examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebd22c6-fad4-4ead-aceb-dd1b2100f4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of tasks with bad examples\n",
    "print('bad examples names:')\n",
    "print(bad_examples_names)\n",
    "print(f\"#bad examples names: {len(bad_examples_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf8932d-6110-4eea-adb7-2dd0dc31dc1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# iterate through all tasks and get sentence dataset\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "nlp = spacy.load('de_core_news_lg')\n",
    "nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n",
    "task_cursor = db.task.find({})\n",
    "\n",
    "de_data = []\n",
    "en_data = []\n",
    "counter = 0\n",
    "\n",
    "for task in tqdm(task_cursor):\n",
    "    \n",
    "    # get text and id of task\n",
    "    text = task['text']\n",
    "    doc_id = task['_id']\n",
    "    \n",
    "    # find all annotations of this task and extract them\n",
    "    annotation_cursor = db.annotation.find({'task': doc_id, 'label': {'$regex': 'Right to.*'}})\n",
    "    annotations = []\n",
    "    for annotation in annotation_cursor:\n",
    "        annotations.append({'start': annotation['start'], 'end': annotation['end'], 'label': annotation['label'], 'text': annotation['text']})\n",
    "        \n",
    "    if not annotations:\n",
    "        continue\n",
    "        \n",
    "    # iterate over text and save sentences\n",
    "    doc = nlp(text)\n",
    "    for sentence in list(doc.sents):\n",
    "        is_sentence_appended = False\n",
    "        sentence_start = len(text.split(str(sentence))[0]) + 1\n",
    "        sentence_end = sentence_start + len(str(sentence))\n",
    "        for annotation in annotations:\n",
    "            if sentence_start <= annotation['start'] <= sentence_end or\\\n",
    "                sentence_start <= annotation['end'] <= sentence_end or\\\n",
    "                annotation['start'] <= sentence_start <= annotation['end'] or\\\n",
    "                annotation['start'] <= sentence_end <= annotation['end']:\n",
    "                    if sentence._.language['en']:\n",
    "                        en_data.append({'sentence': str(sentence), 'label': annotation['label']})\n",
    "                        is_sentence_appended = True\n",
    "                    elif sentence._.language['de']:\n",
    "                        de_data.append({'sentence': str(sentence), 'label': annotation['label']})\n",
    "                        is_sentence_appended = True\n",
    "        if not is_sentence_appended:\n",
    "            if sentence._.language['en']:\n",
    "                en_data.append({'sentence': str(sentence), 'label': annotation['label']})\n",
    "            elif sentence._.language['de']:\n",
    "                de_data.append({'sentence': str(sentence), 'label': annotation['label']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa160bbd-da7b-4029-8666-804680514594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "import pandas\n",
    "\n",
    "de_df = pandas.DataFrame.from_dict(de_data)\n",
    "print(de_df)\n",
    "en_df = pandas.DataFrame.from_dict(en_data)\n",
    "print(en_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc2c27-a5ad-4d56-bc2f-6b50665b0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv files\n",
    "de_df.to_csv('~/Documents/DaSKITA/playground/tiltify/data/de_sentence_data.csv')\n",
    "en_df.to_csv('~/Documents/DaSKITA/playground/tiltify/data/en_sentence_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
