{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Variables not found. Entering Test Mode!\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from tiltify.models.gaussian_nb_model import GaussianNBModel\n",
    "from tiltify.models.sentence_bert import SentenceBert\n",
    "from tiltify.models.binary_bert_model import BinaryBERTModel\n",
    "\n",
    "\n",
    "results_folder = \"/home/gebauer/Desktop/repo/tiltify/experiments/IWPE/results_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sizes: [1]\n",
      "Corpus having: 20 Test Docs and 40 Train Docs.\n"
     ]
    }
   ],
   "source": [
    "from tiltify.data_structures.document_collection import DocumentCollection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "config = {\n",
    "    \"k_ranks\": [5, 10, 25],\n",
    "    \"repitions\": 2,\n",
    "    \"step_size\": 2,\n",
    "    \"random_state\": 1337\n",
    "}\n",
    "\n",
    "step_size = config[\"step_size\"]\n",
    "train_doc_sizes = [1]  # [size/10 for size in list(range(0, 10+step_size, step_size))][1:]\n",
    "print(f\"Training Sizes: {train_doc_sizes}\")\n",
    "\n",
    "document_collection = DocumentCollection.from_json_files()\n",
    "doc_index = list(range(len(document_collection)))\n",
    "\n",
    "train_docs, test_docs = train_test_split(\n",
    "    doc_index, test_size=0.33, random_state=config[\"random_state\"], shuffle=False)\n",
    "train_docs = document_collection[train_docs]\n",
    "test_set = document_collection[test_docs]\n",
    "print(f\"Corpus having: {len(test_docs)} Test Docs and {len(train_docs)} Train Docs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def eval_model(model, doc_set):\n",
    "    print(f\"Starting evaluation of {model.__class__.__name__}...\")\n",
    "    metrics_dict = {}\n",
    "    \n",
    "\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    for document in tqdm(doc_set):\n",
    "        labels = model.preprocessor.label_retriever.retrieve_labels(document.blobs)\n",
    "        labels = model.preprocessor.prepare_labels(labels)\n",
    "        logits = model.predict(document)\n",
    "        # log_based_preds = [logit > 0.5 for logit in logits]\n",
    "        all_logits.append(logits)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    # metrics_dict[\"all_logits\"] = all_logits\n",
    "    # metrics_dict[\"all_labels\"] = all_labels\n",
    "    all_labels = sum(all_labels, [])\n",
    "    all_logits = sum(all_logits, [])\n",
    "    \n",
    "    return all_logits, all_labels\n",
    "\n",
    "# def brier_scores(true, preds, weights=None):\n",
    "#     bs = np.subtract(preds, true)**2\n",
    "#     if min(preds) < 0:\n",
    "#         raise AttributeError(f\"Some predictions are below zero: {min(preds)}\")\n",
    "    \n",
    "#     if weights:\n",
    "#         bs = np.matmul(bs, weights.T)\n",
    "#     else:\n",
    "#         bs = bs.mean()\n",
    "#     return bs\n",
    "\n",
    "def min_max_norm(values):\n",
    "    max_val = 1\n",
    "    min_val = -1\n",
    "    new_vals = []\n",
    "    for val in values:\n",
    "        new_val = (val - min_val)/(max_val - min_val)\n",
    "        new_vals.append(new_val)\n",
    "    return new_vals\n",
    "\n",
    "def norm_sim(values):\n",
    "    new_vals = []\n",
    "    for val in values:\n",
    "        new_val = (val + 1)/2\n",
    "        new_vals.append(new_val)\n",
    "    return new_vals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation of SentenceBert...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:58<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation of SentenceBert...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:25<00:59,  4.28s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 2.95 GiB total capacity; 1.44 GiB already allocated; 131.44 MiB free; 2.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/gebauer/Desktop/repo/tiltify/experiments/IWPE/calibration.ipynb Cell 5\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gebauer/Desktop/repo/tiltify/experiments/IWPE/calibration.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m label \u001b[39m=\u001b[39m load_path\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gebauer/Desktop/repo/tiltify/experiments/IWPE/calibration.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m model \u001b[39m=\u001b[39m model_cls\u001b[39m.\u001b[39mload(load_path, label\u001b[39m=\u001b[39mlabel)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gebauer/Desktop/repo/tiltify/experiments/IWPE/calibration.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m logits, labels \u001b[39m=\u001b[39m eval_model(model, test_set)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gebauer/Desktop/repo/tiltify/experiments/IWPE/calibration.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m save_prefix \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel_cls\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m__\u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gebauer/Desktop/repo/tiltify/experiments/IWPE/calibration.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# metrics_dict[f\"{save_prefix}__bier_score\"].append(brier_scores(norm_labels, logits))\u001b[39;00m\n",
      "\u001b[1;32m/home/gebauer/Desktop/repo/tiltify/experiments/IWPE/calibration.ipynb Cell 5\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(model, doc_set)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gebauer/Desktop/repo/tiltify/experiments/IWPE/calibration.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m labels \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpreprocessor\u001b[39m.\u001b[39mlabel_retriever\u001b[39m.\u001b[39mretrieve_labels(document\u001b[39m.\u001b[39mblobs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gebauer/Desktop/repo/tiltify/experiments/IWPE/calibration.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m labels \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpreprocessor\u001b[39m.\u001b[39mprepare_labels(labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gebauer/Desktop/repo/tiltify/experiments/IWPE/calibration.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m logits \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(document)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gebauer/Desktop/repo/tiltify/experiments/IWPE/calibration.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# log_based_preds = [logit > 0.5 for logit in logits]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gebauer/Desktop/repo/tiltify/experiments/IWPE/calibration.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m all_logits\u001b[39m.\u001b[39mappend(logits)\n",
      "File \u001b[0;32m~/Desktop/repo/tiltify/src/tiltify/models/sentence_bert.py:40\u001b[0m, in \u001b[0;36mSentenceBert.predict\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, document: Document) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m     39\u001b[0m     blob_texts \u001b[39m=\u001b[39m [blob\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m blob \u001b[39min\u001b[39;00m document\u001b[39m.\u001b[39mblobs]\n\u001b[0;32m---> 40\u001b[0m     encoded_corpus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mencode(blob_texts, convert_to_tensor\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     41\u001b[0m     cos_scores \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mcos_sim(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoded_query, encoded_corpus)[\u001b[39m0\u001b[39m]  \u001b[39m# TODO: replace with triplet loss\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[39mreturn\u001b[39;00m cos_scores\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/Desktop/repo/tiltify/.venv/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    162\u001b[0m features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 165\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features)\n\u001b[1;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    168\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/Desktop/repo/tiltify/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/repo/tiltify/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/repo/tiltify/.venv/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[1;32m     64\u001b[0m     trans_features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauto_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrans_features, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     67\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[1;32m     69\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: output_tokens, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: features[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]})\n",
      "File \u001b[0;32m~/Desktop/repo/tiltify/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/repo/tiltify/.venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:996\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    987\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    989\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    990\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    991\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    994\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    995\u001b[0m )\n\u001b[0;32m--> 996\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    997\u001b[0m     embedding_output,\n\u001b[1;32m    998\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    999\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1000\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1001\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1002\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1003\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1004\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1005\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1006\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1007\u001b[0m )\n\u001b[1;32m   1008\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1009\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repo/tiltify/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/repo/tiltify/.venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    576\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    577\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    578\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    583\u001b[0m     )\n\u001b[1;32m    584\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 585\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    586\u001b[0m         hidden_states,\n\u001b[1;32m    587\u001b[0m         attention_mask,\n\u001b[1;32m    588\u001b[0m         layer_head_mask,\n\u001b[1;32m    589\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    590\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    591\u001b[0m         past_key_value,\n\u001b[1;32m    592\u001b[0m         output_attentions,\n\u001b[1;32m    593\u001b[0m     )\n\u001b[1;32m    595\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    596\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Desktop/repo/tiltify/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/repo/tiltify/.venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:472\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    461\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    462\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m ):\n\u001b[1;32m    470\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    473\u001b[0m         hidden_states,\n\u001b[1;32m    474\u001b[0m         attention_mask,\n\u001b[1;32m    475\u001b[0m         head_mask,\n\u001b[1;32m    476\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    477\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    478\u001b[0m     )\n\u001b[1;32m    479\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    481\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repo/tiltify/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/repo/tiltify/.venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:402\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    393\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    394\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    401\u001b[0m ):\n\u001b[0;32m--> 402\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    403\u001b[0m         hidden_states,\n\u001b[1;32m    404\u001b[0m         attention_mask,\n\u001b[1;32m    405\u001b[0m         head_mask,\n\u001b[1;32m    406\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    407\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    408\u001b[0m         past_key_value,\n\u001b[1;32m    409\u001b[0m         output_attentions,\n\u001b[1;32m    410\u001b[0m     )\n\u001b[1;32m    411\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    412\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repo/tiltify/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/repo/tiltify/.venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:324\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    321\u001b[0m         relative_position_scores_key \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m\"\u001b[39m\u001b[39mbhrd,lrd->bhlr\u001b[39m\u001b[39m\"\u001b[39m, key_layer, positional_embedding)\n\u001b[1;32m    322\u001b[0m         attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m+\u001b[39m relative_position_scores_query \u001b[39m+\u001b[39m relative_position_scores_key\n\u001b[0;32m--> 324\u001b[0m attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m/\u001b[39;49m math\u001b[39m.\u001b[39;49msqrt(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention_head_size)\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[39;00m\n\u001b[1;32m    327\u001b[0m     attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m+\u001b[39m attention_mask\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 2.95 GiB total capacity; 1.44 GiB already allocated; 131.44 MiB free; 2.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "all_models = [\n",
    "    SentenceBert,\n",
    "    BinaryBERTModel, \n",
    "    GaussianNBModel\n",
    "    ]\n",
    "\n",
    "metrics_dict = defaultdict(list)\n",
    "for model_cls in all_models:\n",
    "    relevant_path = os.path.join(results_folder, f\"{model_cls.__name__}/Right*/[0-1]\")\n",
    "    all_paths = glob(relevant_path)\n",
    "    for load_path in all_paths:\n",
    "        label = load_path.split(\"/\")[-2]\n",
    "        model = model_cls.load(load_path, label=label)\n",
    "\n",
    "        logits, labels = eval_model(model, test_set)\n",
    "        \n",
    "        save_prefix = f\"{model_cls.__name__}__{label}\"\n",
    "        # metrics_dict[f\"{save_prefix}__bier_score\"].append(brier_scores(norm_labels, logits))\n",
    "        positive_cnt = sum(labels)\n",
    "        negative_cnt = len(labels) - positive_cnt\n",
    "        \n",
    "        weights = [positive_cnt if label > 0 else negative_cnt for label in labels]\n",
    "        if isinstance(model, SentenceBert):\n",
    "            metrics_dict[f\"{save_prefix}__brier_score\"].append(brier_score_loss(labels, norm_sim(logits), sample_weight=weights))\n",
    "        else:\n",
    "            metrics_dict[f\"{save_prefix}__brier_score\"].append(brier_score_loss(labels, logits, sample_weight=weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'BinaryBERTModel__Right to Deletion__brier_score': [0.25527092363491977,\n",
       "              0.24901538831053482],\n",
       "             'BinaryBERTModel__Right to Withdraw Consent__brier_score': [0.26195873466051056,\n",
       "              0.23864607295756182],\n",
       "             'BinaryBERTModel__Right to Information__brier_score': [0.24661778119152072,\n",
       "              0.2519837284729277],\n",
       "             'BinaryBERTModel__Right to Complain__brier_score': [0.2742134296117353,\n",
       "              0.2416008860267396],\n",
       "             'BinaryBERTModel__Right to Data Portability__brier_score': [0.2361551888246405,\n",
       "              0.2433711711622055]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "save_path = \"/home/gebauer/Desktop/repo/tiltify/experiments/IWPE/results_2/brier_scores.json\"\n",
    "\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(metrics_dict, f)\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c00a82eacfe0370be8326cca920297af08c3bb7bdac9e41c299bfef56ad4a128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
